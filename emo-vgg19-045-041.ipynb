{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pickle\nimport joblib\nimport matplotlib.pyplot as plt\nimport librosa, librosa.display\nfrom IPython.display import Audio, FileLink\nfrom pydub import AudioSegment\nimport os\nimport gc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import MaxAbsScaler\n\nfrom tensorflow.keras.layers import Input, Dense, Flatten\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.metrics import Precision, Recall\nfrom tensorflow.keras import regularizers\nfrom tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.activations import softmax\nfrom tensorflow.keras.optimizers import Adam","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-31T16:12:00.784349Z","iopub.execute_input":"2023-10-31T16:12:00.784796Z","iopub.status.idle":"2023-10-31T16:12:09.539720Z","shell.execute_reply.started":"2023-10-31T16:12:00.784756Z","shell.execute_reply":"2023-10-31T16:12:09.538805Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"iemo_data = pd.read_csv('/kaggle/input/iemocap-transcriptions-english-french/iemocapTrans.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:12:09.541939Z","iopub.execute_input":"2023-10-31T16:12:09.542695Z","iopub.status.idle":"2023-10-31T16:12:09.641686Z","shell.execute_reply.started":"2023-10-31T16:12:09.542660Z","shell.execute_reply":"2023-10-31T16:12:09.640732Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"iemo_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:12:09.642941Z","iopub.execute_input":"2023-10-31T16:12:09.643309Z","iopub.status.idle":"2023-10-31T16:12:09.670126Z","shell.execute_reply.started":"2023-10-31T16:12:09.643274Z","shell.execute_reply":"2023-10-31T16:12:09.669234Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                        _id  activation  dominance emotion  end_time  \\\n0  625682441da7a5c1eaef3689         2.5        3.5     sad    6.0541   \n1  625682441da7a5c1eaef368a         3.0        4.0     sad   15.1000   \n2  625682441da7a5c1eaef368b         2.5        4.5     sad   23.3599   \n3  625682441da7a5c1eaef368c         2.5        4.0     sad   26.4151   \n4  625682441da7a5c1eaef368d         3.0        3.5     sad   31.4253   \n\n   start_time                titre  \\\n0      3.9987  Ses02M_impro02_F000   \n1      7.0366  Ses02M_impro02_M000   \n2     15.5524  Ses02M_impro02_F001   \n3     23.5790  Ses02M_impro02_F002   \n4     26.7598  Ses02M_impro02_M001   \n\n                                        to_translate  \\\n0                            I don't want you to go.   \n1   I know, I know. I don't want to go either bab...   \n2   I'm going to miss you too; I don't know what ...   \n3                   I don't want to be a single mom.   \n4   You won't be. I'll be back; I'll be back befo...   \n\n                                          translated  valence  \n0                      Je ne veux pas que tu partes.      2.5  \n1  Je sais je sais. Je ne veux pas y aller non pl...      2.0  \n2  Tu vas me manquer aussi; Je ne sais pas ce que...      1.5  \n3          Je ne veux pas être une mère célibataire.      1.5  \n4  Vous ne le serez pas. Je reviendrai; Je serai ...      3.5  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_id</th>\n      <th>activation</th>\n      <th>dominance</th>\n      <th>emotion</th>\n      <th>end_time</th>\n      <th>start_time</th>\n      <th>titre</th>\n      <th>to_translate</th>\n      <th>translated</th>\n      <th>valence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>625682441da7a5c1eaef3689</td>\n      <td>2.5</td>\n      <td>3.5</td>\n      <td>sad</td>\n      <td>6.0541</td>\n      <td>3.9987</td>\n      <td>Ses02M_impro02_F000</td>\n      <td>I don't want you to go.</td>\n      <td>Je ne veux pas que tu partes.</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>625682441da7a5c1eaef368a</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>sad</td>\n      <td>15.1000</td>\n      <td>7.0366</td>\n      <td>Ses02M_impro02_M000</td>\n      <td>I know, I know. I don't want to go either bab...</td>\n      <td>Je sais je sais. Je ne veux pas y aller non pl...</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>625682441da7a5c1eaef368b</td>\n      <td>2.5</td>\n      <td>4.5</td>\n      <td>sad</td>\n      <td>23.3599</td>\n      <td>15.5524</td>\n      <td>Ses02M_impro02_F001</td>\n      <td>I'm going to miss you too; I don't know what ...</td>\n      <td>Tu vas me manquer aussi; Je ne sais pas ce que...</td>\n      <td>1.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>625682441da7a5c1eaef368c</td>\n      <td>2.5</td>\n      <td>4.0</td>\n      <td>sad</td>\n      <td>26.4151</td>\n      <td>23.5790</td>\n      <td>Ses02M_impro02_F002</td>\n      <td>I don't want to be a single mom.</td>\n      <td>Je ne veux pas être une mère célibataire.</td>\n      <td>1.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>625682441da7a5c1eaef368d</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>sad</td>\n      <td>31.4253</td>\n      <td>26.7598</td>\n      <td>Ses02M_impro02_M001</td>\n      <td>You won't be. I'll be back; I'll be back befo...</td>\n      <td>Vous ne le serez pas. Je reviendrai; Je serai ...</td>\n      <td>3.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"iemo_data = iemo_data[['emotion', 'titre']]\niemo_data['filepath'] = '/kaggle/input/iemocap-transcriptions-english-french/Iemocap_audio/iemocap_audio/IEMOCAP_wav/' + iemo_data['titre'] + '.wav'","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:12:09.671222Z","iopub.execute_input":"2023-10-31T16:12:09.671555Z","iopub.status.idle":"2023-10-31T16:12:09.689561Z","shell.execute_reply.started":"2023-10-31T16:12:09.671520Z","shell.execute_reply":"2023-10-31T16:12:09.688505Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# ravdess dataset\n# emotions -> 01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised\n# third part of the name\n\nemo_dict = {\n    '01': 'neu',\n    '02': 'neu',\n    '03': 'hap',\n    '04': 'sad',\n    '05': 'ang',\n    '06': 'fea',\n    '07': 'dis',\n    '08': 'sur'\n}\n\nravdess_base = \"/kaggle/input/ravdess-emotional-speech-audio/\"\n\nrav_data = pd.DataFrame(columns=['emotion', 'titre', 'filepath'])\n\nfor dirname, _, filenames in os.walk(ravdess_base):\n    for filename in filenames:\n        \n        info_list = filename.split('-')\n        emotion = emo_dict[info_list[2]]\n                \n        new_row = {\n            'emotion': [emotion],\n            'titre': [filename[:-4]],\n            'filepath': [os.path.join(dirname, filename)]\n        }\n        rav_data = pd.concat([rav_data, pd.DataFrame(new_row)], ignore_index=True)\nrav_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:12:09.692203Z","iopub.execute_input":"2023-10-31T16:12:09.692471Z","iopub.status.idle":"2023-10-31T16:12:12.301495Z","shell.execute_reply.started":"2023-10-31T16:12:09.692447Z","shell.execute_reply":"2023-10-31T16:12:12.300480Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"  emotion                 titre  \\\n0     sur  03-01-08-01-01-01-02   \n1     neu  03-01-01-01-01-01-02   \n2     dis  03-01-07-02-01-02-02   \n3     dis  03-01-07-01-01-02-02   \n4     neu  03-01-01-01-02-01-02   \n\n                                            filepath  \n0  /kaggle/input/ravdess-emotional-speech-audio/A...  \n1  /kaggle/input/ravdess-emotional-speech-audio/A...  \n2  /kaggle/input/ravdess-emotional-speech-audio/A...  \n3  /kaggle/input/ravdess-emotional-speech-audio/A...  \n4  /kaggle/input/ravdess-emotional-speech-audio/A...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>emotion</th>\n      <th>titre</th>\n      <th>filepath</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sur</td>\n      <td>03-01-08-01-01-01-02</td>\n      <td>/kaggle/input/ravdess-emotional-speech-audio/A...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>neu</td>\n      <td>03-01-01-01-01-01-02</td>\n      <td>/kaggle/input/ravdess-emotional-speech-audio/A...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>dis</td>\n      <td>03-01-07-02-01-02-02</td>\n      <td>/kaggle/input/ravdess-emotional-speech-audio/A...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>dis</td>\n      <td>03-01-07-01-01-02-02</td>\n      <td>/kaggle/input/ravdess-emotional-speech-audio/A...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>neu</td>\n      <td>03-01-01-01-02-01-02</td>\n      <td>/kaggle/input/ravdess-emotional-speech-audio/A...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data = pd.concat([iemo_data, rav_data], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:12:12.302792Z","iopub.execute_input":"2023-10-31T16:12:12.303117Z","iopub.status.idle":"2023-10-31T16:12:12.308705Z","shell.execute_reply.started":"2023-10-31T16:12:12.303089Z","shell.execute_reply":"2023-10-31T16:12:12.307649Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data = data.sample(frac=1)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:12:12.309940Z","iopub.execute_input":"2023-10-31T16:12:12.310317Z","iopub.status.idle":"2023-10-31T16:12:12.322190Z","shell.execute_reply.started":"2023-10-31T16:12:12.310290Z","shell.execute_reply":"2023-10-31T16:12:12.321364Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def show_cat(df):\n    print('sad', df.emotion.loc[df.emotion == 'sad'].count())\n    print('fru', df.emotion.loc[df.emotion == 'fru'].count())\n    print('neu', df.emotion.loc[df.emotion == 'neu'].count())\n    print('hap', df.emotion.loc[df.emotion == 'hap'].count())\n    print('exc', df.emotion.loc[df.emotion == 'exc'].count())\n    print('sur', df.emotion.loc[df.emotion == 'sur'].count())\n    print('ang', df.emotion.loc[df.emotion == 'ang'].count())\n    print('fea', df.emotion.loc[df.emotion == 'fea'].count())\n    print('oth', df.emotion.loc[df.emotion == 'oth'].count())\n    print('dis', df.emotion.loc[df.emotion == 'dis'].count())\n    \nshow_cat(data)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:12:12.323285Z","iopub.execute_input":"2023-10-31T16:12:12.323604Z","iopub.status.idle":"2023-10-31T16:12:12.359273Z","shell.execute_reply.started":"2023-10-31T16:12:12.323570Z","shell.execute_reply":"2023-10-31T16:12:12.358402Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"sad 1634\nfru 2917\nneu 2302\nhap 1040\nexc 1976\nsur 494\nang 1653\nfea 491\noth 26\ndis 386\n","output_type":"stream"}]},{"cell_type":"code","source":"data = pd.get_dummies(data, columns=['emotion'], dtype='int')\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:12:12.360275Z","iopub.execute_input":"2023-10-31T16:12:12.360588Z","iopub.status.idle":"2023-10-31T16:12:12.382483Z","shell.execute_reply.started":"2023-10-31T16:12:12.360556Z","shell.execute_reply":"2023-10-31T16:12:12.381720Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                       titre  \\\n5422  Ses02M_script03_1_M027   \n198   Ses03M_script03_2_M044   \n7555  Ses03F_script03_1_M014   \n1483  Ses05M_script03_1_F009   \n8604  Ses01M_script03_1_F016   \n\n                                               filepath  emotion_ang  \\\n5422  /kaggle/input/iemocap-transcriptions-english-f...            0   \n198   /kaggle/input/iemocap-transcriptions-english-f...            1   \n7555  /kaggle/input/iemocap-transcriptions-english-f...            0   \n1483  /kaggle/input/iemocap-transcriptions-english-f...            0   \n8604  /kaggle/input/iemocap-transcriptions-english-f...            0   \n\n      emotion_dis  emotion_exc  emotion_fea  emotion_fru  emotion_hap  \\\n5422            0            1            0            0            0   \n198             0            0            0            0            0   \n7555            0            1            0            0            0   \n1483            0            1            0            0            0   \n8604            0            1            0            0            0   \n\n      emotion_neu  emotion_oth  emotion_sad  emotion_sur  \n5422            0            0            0            0  \n198             0            0            0            0  \n7555            0            0            0            0  \n1483            0            0            0            0  \n8604            0            0            0            0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>titre</th>\n      <th>filepath</th>\n      <th>emotion_ang</th>\n      <th>emotion_dis</th>\n      <th>emotion_exc</th>\n      <th>emotion_fea</th>\n      <th>emotion_fru</th>\n      <th>emotion_hap</th>\n      <th>emotion_neu</th>\n      <th>emotion_oth</th>\n      <th>emotion_sad</th>\n      <th>emotion_sur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5422</th>\n      <td>Ses02M_script03_1_M027</td>\n      <td>/kaggle/input/iemocap-transcriptions-english-f...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>Ses03M_script03_2_M044</td>\n      <td>/kaggle/input/iemocap-transcriptions-english-f...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7555</th>\n      <td>Ses03F_script03_1_M014</td>\n      <td>/kaggle/input/iemocap-transcriptions-english-f...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1483</th>\n      <td>Ses05M_script03_1_F009</td>\n      <td>/kaggle/input/iemocap-transcriptions-english-f...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8604</th>\n      <td>Ses01M_script03_1_F016</td>\n      <td>/kaggle/input/iemocap-transcriptions-english-f...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def add_noise(data, noise_factor):\n    noise = np.random.randn(len(data))\n    noice_data = data + noise_factor * noise\n    noice_data = noice_data.astype(type(data[0]))\n    return noice_data\n\ndef change_pitch(data, sampling_rate, n_steps=3):\n    return librosa.effects.pitch_shift(data, sr=sampling_rate, n_steps=n_steps)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:12:12.383507Z","iopub.execute_input":"2023-10-31T16:12:12.383807Z","iopub.status.idle":"2023-10-31T16:12:12.389470Z","shell.execute_reply.started":"2023-10-31T16:12:12.383782Z","shell.execute_reply":"2023-10-31T16:12:12.388593Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def audio_to_stft(filepath, emotions, sample_rate):\n    \n    arr_len = 3*sample_rate\n    arr, sr = librosa.load(filepath, sr=sample_rate)\n    \n    audios = []\n    \n    while (arr.shape[0] >= sample_rate):\n        \n        if arr.shape[0] < arr_len:\n            \n            arr = np.pad(arr, (0, arr_len-arr.shape[0]), 'constant')\n            \n#             if ((emotions['emotion_sur'] == 1) | (emotions['emotion_fea'] == 1) | (emotions['emotion_dis'] == 1)):\n    #                 # create noice audio\n    #                 noise_audio = add_noise(arr, 0.0001)\n    #                 audios.append(librosa.amplitude_to_db(np.abs(librosa.core.stft(noise_audio, n_fft=1024, hop_length=512))))\n#                 # change pitch of audio\n#                 pitch_audio = change_pitch(arr, sr)\n#                 audios.append(librosa.amplitude_to_db(np.abs(librosa.core.stft(pitch_audio, n_fft=1024, hop_length=512))))\n            audios.append(librosa.amplitude_to_db(np.abs(librosa.core.stft(arr, n_fft=1024, hop_length=512))))\n            arr = np.zeros(0)\n\n        else:\n                    \n            seg = arr[:arr_len]\n#             if ((emotions['emotion_sur'] == 1) | (emotions['emotion_fea'] == 1) | (emotions['emotion_dis'] == 1)):\n#                 # create noice audio\n#                 noise_audio = add_noise(seg, 0.0001)\n#                 audios.append(librosa.amplitude_to_db(np.abs(librosa.core.stft(noise_audio, n_fft=1024, hop_length=512))))\n#                 # change pitch of audio\n#                 pitch_audio = change_pitch(seg, sr)\n#                 audios.append(librosa.amplitude_to_db(np.abs(librosa.core.stft(pitch_audio, n_fft=1024, hop_length=512))))\n            audios.append(librosa.amplitude_to_db(np.abs(librosa.core.stft(seg, n_fft=1024, hop_length=512))))\n            arr = arr[arr_len:]\n            \n    return audios","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:12:12.390557Z","iopub.execute_input":"2023-10-31T16:12:12.390822Z","iopub.status.idle":"2023-10-31T16:12:12.404379Z","shell.execute_reply.started":"2023-10-31T16:12:12.390800Z","shell.execute_reply":"2023-10-31T16:12:12.403656Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"X = []\ny = []\n\nfor _, row in data.iterrows():\n\n    audios = audio_to_stft(row['filepath'], row.drop(['filepath', 'titre']), 22500)\n    \n    for audio in audios:\n        \n        # adding normal audio\n        X.append(audio.reshape(171, -1, 3))\n        y.append(row.drop(['filepath', 'titre']))","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:12:12.405432Z","iopub.execute_input":"2023-10-31T16:12:12.405713Z","iopub.status.idle":"2023-10-31T16:17:02.582838Z","shell.execute_reply.started":"2023-10-31T16:12:12.405690Z","shell.execute_reply":"2023-10-31T16:17:02.581982Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"del data, iemo_data, rav_data\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:17:02.583888Z","iopub.execute_input":"2023-10-31T16:17:02.584443Z","iopub.status.idle":"2023-10-31T16:17:02.899790Z","shell.execute_reply.started":"2023-10-31T16:17:02.584417Z","shell.execute_reply":"2023-10-31T16:17:02.898823Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"max = 0\nfor x in X:\n    max1 = np.max(np.abs(x))\n    if max < max1:\n        max = max1","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:17:02.903720Z","iopub.execute_input":"2023-10-31T16:17:02.904022Z","iopub.status.idle":"2023-10-31T16:17:03.725913Z","shell.execute_reply.started":"2023-10-31T16:17:02.903996Z","shell.execute_reply":"2023-10-31T16:17:03.724910Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"X_np = np.array(X, dtype=np.float16) / max\ny_np = np.array(y, dtype=np.float16)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:17:03.727081Z","iopub.execute_input":"2023-10-31T16:17:03.727373Z","iopub.status.idle":"2023-10-31T16:17:26.286487Z","shell.execute_reply.started":"2023-10-31T16:17:03.727347Z","shell.execute_reply":"2023-10-31T16:17:26.285662Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"SPEC_SHAPE = X_np.shape[1:-1]\nSPEC_SHAPE","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:17:26.288308Z","iopub.execute_input":"2023-10-31T16:17:26.288604Z","iopub.status.idle":"2023-10-31T16:17:26.294535Z","shell.execute_reply.started":"2023-10-31T16:17:26.288572Z","shell.execute_reply":"2023-10-31T16:17:26.293682Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(171, 132)"},"metadata":{}}]},{"cell_type":"code","source":"size = X_np.shape[0]","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:17:26.295859Z","iopub.execute_input":"2023-10-31T16:17:26.296203Z","iopub.status.idle":"2023-10-31T16:17:26.306401Z","shell.execute_reply.started":"2023-10-31T16:17:26.296171Z","shell.execute_reply":"2023-10-31T16:17:26.305651Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"X_train = np.copy(X_np[:int(size*0.9)])\ny_train = np.copy(y_np[:int(size*0.9)])\nX_test = np.copy(X_np[int(size*0.9):])\ny_test = np.copy(y_np[int(size*0.9):])","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:17:26.307590Z","iopub.execute_input":"2023-10-31T16:17:26.307961Z","iopub.status.idle":"2023-10-31T16:17:27.239965Z","shell.execute_reply.started":"2023-10-31T16:17:26.307904Z","shell.execute_reply":"2023-10-31T16:17:27.239152Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del X_np\ndel y_np\ndel X\ndel y\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:17:27.241130Z","iopub.execute_input":"2023-10-31T16:17:27.241418Z","iopub.status.idle":"2023-10-31T16:17:27.533812Z","shell.execute_reply.started":"2023-10-31T16:17:27.241392Z","shell.execute_reply":"2023-10-31T16:17:27.532890Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"# Xtr, Xte, ytr, yte = train_test_split(X_np, y_np, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:17:27.534989Z","iopub.execute_input":"2023-10-31T16:17:27.535342Z","iopub.status.idle":"2023-10-31T16:17:27.544225Z","shell.execute_reply.started":"2023-10-31T16:17:27.535308Z","shell.execute_reply":"2023-10-31T16:17:27.543353Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"resnet50 = VGG19(\n    include_top = False, \n    weights = 'imagenet',\n    input_shape=SPEC_SHAPE + (3,),\n)\n\n# freeze layers\nfor layer in resnet50.layers:\n    layer.trainable = False\n    \nx = Flatten()(resnet50.output)\npred_layer = Dense(10, activation='sigmoid')(x)\n\nmodel = Model(inputs=resnet50.input, outputs=pred_layer)\nmodel.summary()\n        ","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:17:27.545383Z","iopub.execute_input":"2023-10-31T16:17:27.546899Z","iopub.status.idle":"2023-10-31T16:17:31.218559Z","shell.execute_reply.started":"2023-10-31T16:17:27.546863Z","shell.execute_reply":"2023-10-31T16:17:31.217683Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n80134624/80134624 [==============================] - 0s 0us/step\nModel: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 171, 132, 3)]     0         \n                                                                 \n block1_conv1 (Conv2D)       (None, 171, 132, 64)      1792      \n                                                                 \n block1_conv2 (Conv2D)       (None, 171, 132, 64)      36928     \n                                                                 \n block1_pool (MaxPooling2D)  (None, 85, 66, 64)        0         \n                                                                 \n block2_conv1 (Conv2D)       (None, 85, 66, 128)       73856     \n                                                                 \n block2_conv2 (Conv2D)       (None, 85, 66, 128)       147584    \n                                                                 \n block2_pool (MaxPooling2D)  (None, 42, 33, 128)       0         \n                                                                 \n block3_conv1 (Conv2D)       (None, 42, 33, 256)       295168    \n                                                                 \n block3_conv2 (Conv2D)       (None, 42, 33, 256)       590080    \n                                                                 \n block3_conv3 (Conv2D)       (None, 42, 33, 256)       590080    \n                                                                 \n block3_conv4 (Conv2D)       (None, 42, 33, 256)       590080    \n                                                                 \n block3_pool (MaxPooling2D)  (None, 21, 16, 256)       0         \n                                                                 \n block4_conv1 (Conv2D)       (None, 21, 16, 512)       1180160   \n                                                                 \n block4_conv2 (Conv2D)       (None, 21, 16, 512)       2359808   \n                                                                 \n block4_conv3 (Conv2D)       (None, 21, 16, 512)       2359808   \n                                                                 \n block4_conv4 (Conv2D)       (None, 21, 16, 512)       2359808   \n                                                                 \n block4_pool (MaxPooling2D)  (None, 10, 8, 512)        0         \n                                                                 \n block5_conv1 (Conv2D)       (None, 10, 8, 512)        2359808   \n                                                                 \n block5_conv2 (Conv2D)       (None, 10, 8, 512)        2359808   \n                                                                 \n block5_conv3 (Conv2D)       (None, 10, 8, 512)        2359808   \n                                                                 \n block5_conv4 (Conv2D)       (None, 10, 8, 512)        2359808   \n                                                                 \n block5_pool (MaxPooling2D)  (None, 5, 4, 512)         0         \n                                                                 \n flatten (Flatten)           (None, 10240)             0         \n                                                                 \n dense (Dense)               (None, 10)                102410    \n                                                                 \n=================================================================\nTotal params: 20,126,794\nTrainable params: 102,410\nNon-trainable params: 20,024,384\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(\n    loss='categorical_crossentropy',\n    optimizer=Adam(learning_rate=1e-3),\n    metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:27:41.448304Z","iopub.execute_input":"2023-10-31T16:27:41.448743Z","iopub.status.idle":"2023-10-31T16:27:41.462492Z","shell.execute_reply.started":"2023-10-31T16:27:41.448708Z","shell.execute_reply":"2023-10-31T16:27:41.461663Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# early_stopper = EarlyStopping(monitor = 'val_loss', patience = 3)\n# model_save = ModelCheckpoint(filepath='models/', monitor='val_losss')","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:27:41.666882Z","iopub.execute_input":"2023-10-31T16:27:41.667241Z","iopub.status.idle":"2023-10-31T16:27:41.671523Z","shell.execute_reply.started":"2023-10-31T16:27:41.667211Z","shell.execute_reply":"2023-10-31T16:27:41.670542Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"fit_history = model.fit(X_train, y_train, epochs=6, validation_data=(X_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:27:42.127778Z","iopub.execute_input":"2023-10-31T16:27:42.128740Z","iopub.status.idle":"2023-10-31T16:30:37.408815Z","shell.execute_reply.started":"2023-10-31T16:27:42.128705Z","shell.execute_reply":"2023-10-31T16:30:37.407829Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Epoch 1/6\n569/569 [==============================] - 29s 49ms/step - loss: 1.5970 - accuracy: 0.3859 - val_loss: 2.6712 - val_accuracy: 0.3732\nEpoch 2/6\n569/569 [==============================] - 27s 47ms/step - loss: 1.5299 - accuracy: 0.4138 - val_loss: 3.4023 - val_accuracy: 0.3673\nEpoch 3/6\n569/569 [==============================] - 27s 47ms/step - loss: 1.5077 - accuracy: 0.4251 - val_loss: 3.5265 - val_accuracy: 0.4118\nEpoch 4/6\n569/569 [==============================] - 27s 47ms/step - loss: 1.4765 - accuracy: 0.4376 - val_loss: 3.7404 - val_accuracy: 0.4162\nEpoch 5/6\n569/569 [==============================] - 26s 46ms/step - loss: 1.4312 - accuracy: 0.4545 - val_loss: 4.1229 - val_accuracy: 0.3925\nEpoch 6/6\n569/569 [==============================] - 27s 47ms/step - loss: 1.4216 - accuracy: 0.4507 - val_loss: 4.1932 - val_accuracy: 0.4128\n","output_type":"stream"}]},{"cell_type":"code","source":"# model.evaluate(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:18:20.691050Z","iopub.execute_input":"2023-10-31T16:18:20.691437Z","iopub.status.idle":"2023-10-31T16:18:20.697770Z","shell.execute_reply.started":"2023-10-31T16:18:20.691403Z","shell.execute_reply":"2023-10-31T16:18:20.695281Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model.save('modelvgg19-without-noice-0.44.h5') # 0.44 -> 0.40\njoblib.dump(model, 'modelvgg19-without-noice-0.44.pkl')","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:18:20.701536Z","iopub.execute_input":"2023-10-31T16:18:20.701883Z","iopub.status.idle":"2023-10-31T16:18:21.222907Z","shell.execute_reply.started":"2023-10-31T16:18:20.701847Z","shell.execute_reply":"2023-10-31T16:18:21.221892Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"['modelvgg19-without-noice-0.44.pkl']"},"metadata":{}}]},{"cell_type":"code","source":"FileLink('modelvgg19-without-noice-0.44.h5')","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:18:21.224039Z","iopub.execute_input":"2023-10-31T16:18:21.224335Z","iopub.status.idle":"2023-10-31T16:18:21.230370Z","shell.execute_reply.started":"2023-10-31T16:18:21.224308Z","shell.execute_reply":"2023-10-31T16:18:21.229376Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/modelvgg19-without-noice-0.44.h5","text/html":"<a href='modelvgg19-without-noice-0.44.h5' target='_blank'>modelvgg19-without-noice-0.44.h5</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"FileLink('modelvgg19-without-noice-0.44.pkl')","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:18:21.231587Z","iopub.execute_input":"2023-10-31T16:18:21.231902Z","iopub.status.idle":"2023-10-31T16:18:21.244333Z","shell.execute_reply.started":"2023-10-31T16:18:21.231877Z","shell.execute_reply":"2023-10-31T16:18:21.243478Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/modelvgg19-without-noice-0.44.pkl","text/html":"<a href='modelvgg19-without-noice-0.44.pkl' target='_blank'>modelvgg19-without-noice-0.44.pkl</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}