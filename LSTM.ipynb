{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport librosa, librosa.display\nfrom IPython.display import Audio\nfrom pydub import AudioSegment\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as func","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-01T04:31:28.565289Z","iopub.execute_input":"2023-11-01T04:31:28.565726Z","iopub.status.idle":"2023-11-01T04:31:33.939083Z","shell.execute_reply.started":"2023-11-01T04:31:28.565688Z","shell.execute_reply":"2023-11-01T04:31:33.937864Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"iemo_data = pd.read_csv('/kaggle/input/iemocap-transcriptions-english-french/iemocapTrans.csv')\niemo_data = iemo_data[['emotion', 'titre']]\niemo_data['filepath'] = '/kaggle/input/iemocap-transcriptions-english-french/Iemocap_audio/iemocap_audio/IEMOCAP_wav/' + iemo_data['titre'] + '.wav'","metadata":{"execution":{"iopub.status.busy":"2023-11-01T04:31:33.940973Z","iopub.execute_input":"2023-11-01T04:31:33.941460Z","iopub.status.idle":"2023-11-01T04:31:34.065501Z","shell.execute_reply.started":"2023-11-01T04:31:33.941427Z","shell.execute_reply":"2023-11-01T04:31:34.064405Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# ravdess dataset\n# emotions -> 01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised\n# third part of the name\n\nemo_dict = {\n    '01': 'neu',\n    '02': 'neu',\n    '03': 'hap',\n    '04': 'sad',\n    '05': 'ang',\n    '06': 'fea',\n    '07': 'dis',\n    '08': 'sur'\n}\n\nravdess_base = \"/kaggle/input/ravdess-emotional-speech-audio/\"\n\nrav_data = pd.DataFrame(columns=['emotion', 'titre', 'filepath'])\n\nfor dirname, _, filenames in os.walk(ravdess_base):\n    for filename in filenames:\n        \n        info_list = filename.split('-')\n        emotion = emo_dict[info_list[2]]\n                \n        new_row = {\n            'emotion': [emotion],\n            'titre': [filename[:-4]],\n            'filepath': [os.path.join(dirname, filename)]\n        }\n        rav_data = pd.concat([rav_data, pd.DataFrame(new_row)], ignore_index=True)\nrav_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T04:31:34.066865Z","iopub.execute_input":"2023-11-01T04:31:34.067262Z","iopub.status.idle":"2023-11-01T04:31:36.287984Z","shell.execute_reply.started":"2023-11-01T04:31:34.067234Z","shell.execute_reply":"2023-11-01T04:31:36.286611Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"  emotion                 titre  \\\n0     sur  03-01-08-01-01-01-02   \n1     neu  03-01-01-01-01-01-02   \n2     dis  03-01-07-02-01-02-02   \n3     dis  03-01-07-01-01-02-02   \n4     neu  03-01-01-01-02-01-02   \n\n                                            filepath  \n0  /kaggle/input/ravdess-emotional-speech-audio/A...  \n1  /kaggle/input/ravdess-emotional-speech-audio/A...  \n2  /kaggle/input/ravdess-emotional-speech-audio/A...  \n3  /kaggle/input/ravdess-emotional-speech-audio/A...  \n4  /kaggle/input/ravdess-emotional-speech-audio/A...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>emotion</th>\n      <th>titre</th>\n      <th>filepath</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sur</td>\n      <td>03-01-08-01-01-01-02</td>\n      <td>/kaggle/input/ravdess-emotional-speech-audio/A...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>neu</td>\n      <td>03-01-01-01-01-01-02</td>\n      <td>/kaggle/input/ravdess-emotional-speech-audio/A...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>dis</td>\n      <td>03-01-07-02-01-02-02</td>\n      <td>/kaggle/input/ravdess-emotional-speech-audio/A...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>dis</td>\n      <td>03-01-07-01-01-02-02</td>\n      <td>/kaggle/input/ravdess-emotional-speech-audio/A...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>neu</td>\n      <td>03-01-01-01-02-01-02</td>\n      <td>/kaggle/input/ravdess-emotional-speech-audio/A...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data = pd.concat([iemo_data, rav_data], ignore_index=True)\ndata = data.sample(frac=1)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T04:31:36.291045Z","iopub.execute_input":"2023-11-01T04:31:36.291601Z","iopub.status.idle":"2023-11-01T04:31:36.302161Z","shell.execute_reply.started":"2023-11-01T04:31:36.291555Z","shell.execute_reply":"2023-11-01T04:31:36.300753Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data = pd.get_dummies(data, columns=['emotion'], dtype='int')","metadata":{"execution":{"iopub.status.busy":"2023-11-01T04:31:36.304098Z","iopub.execute_input":"2023-11-01T04:31:36.304612Z","iopub.status.idle":"2023-11-01T04:31:36.324237Z","shell.execute_reply.started":"2023-11-01T04:31:36.304565Z","shell.execute_reply":"2023-11-01T04:31:36.323100Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"X = []\ny = []\n\nfor _, row in data.iterrows():\n    \n    arr_len = 48000\n    \n    signal, sr = librosa.load(row['filepath'], sr=16000)\n    arr = np.array(signal)\n    \n    while (arr.shape[0] >= arr_len//3):\n        \n        \n        if (arr.shape[0] < arr_len):\n            \n            pad_len = arr_len - arr.shape[0]\n            arr = np.pad(arr, (0, pad_len), 'constant')\n            assert arr_len == arr.shape[0]\n            X.append(arr.reshape(300,160))\n            y.append(row.drop(['titre', 'filepath']).to_numpy(dtype=np.float32))\n            arr = np.zeros(0)\n            \n        else:\n            \n            segment = arr[: arr_len]\n            assert arr_len == segment.shape[0]\n            X.append(segment.reshape(300,160))\n            y.append(row.drop(['titre', 'filepath']).to_numpy(dtype=np.float32))\n            arr = arr[arr_len:]","metadata":{"execution":{"iopub.status.busy":"2023-11-01T04:31:36.326145Z","iopub.execute_input":"2023-11-01T04:31:36.326765Z","iopub.status.idle":"2023-11-01T04:35:12.573863Z","shell.execute_reply.started":"2023-11-01T04:31:36.326728Z","shell.execute_reply":"2023-11-01T04:35:12.572652Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"X_np = np.array(X)\ny_np = np.array(y)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T04:35:12.575419Z","iopub.execute_input":"2023-11-01T04:35:12.576183Z","iopub.status.idle":"2023-11-01T04:35:14.623581Z","shell.execute_reply.started":"2023-11-01T04:35:12.576140Z","shell.execute_reply":"2023-11-01T04:35:14.622606Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"X_np.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-01T04:35:14.624908Z","iopub.execute_input":"2023-11-01T04:35:14.625313Z","iopub.status.idle":"2023-11-01T04:35:14.632421Z","shell.execute_reply.started":"2023-11-01T04:35:14.625273Z","shell.execute_reply":"2023-11-01T04:35:14.631686Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(20222, 300, 160)"},"metadata":{}}]},{"cell_type":"code","source":"Xtr, Xte, ytr, yte = train_test_split(X_np, y_np, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T04:35:14.633841Z","iopub.execute_input":"2023-11-01T04:35:14.634459Z","iopub.status.idle":"2023-11-01T04:35:17.054102Z","shell.execute_reply.started":"2023-11-01T04:35:14.634427Z","shell.execute_reply":"2023-11-01T04:35:17.052794Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"X_train = torch.tensor(Xtr)\nX_test = torch.tensor(Xte)\ny_train = torch.tensor(ytr)\ny_test = torch.tensor(yte)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T04:35:17.057893Z","iopub.execute_input":"2023-11-01T04:35:17.058799Z","iopub.status.idle":"2023-11-01T04:35:20.029811Z","shell.execute_reply.started":"2023-11-01T04:35:17.058754Z","shell.execute_reply":"2023-11-01T04:35:20.028579Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nnum_epochs = 5\ninput_size = 160\nsequence_length = 300\nlr = 1e-5","metadata":{"execution":{"iopub.status.busy":"2023-11-01T04:35:20.031370Z","iopub.execute_input":"2023-11-01T04:35:20.031745Z","iopub.status.idle":"2023-11-01T04:35:20.037126Z","shell.execute_reply.started":"2023-11-01T04:35:20.031711Z","shell.execute_reply":"2023-11-01T04:35:20.036015Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"loaders = {\n    'train': torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=False),\n    'test': torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_test, y_test), batch_size=batch_size)\n}","metadata":{"execution":{"iopub.status.busy":"2023-11-01T04:35:20.038589Z","iopub.execute_input":"2023-11-01T04:35:20.038972Z","iopub.status.idle":"2023-11-01T04:35:20.050824Z","shell.execute_reply.started":"2023-11-01T04:35:20.038937Z","shell.execute_reply":"2023-11-01T04:35:20.049577Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# rnn\nclass LSTM(nn.Module):\n    \n    def __init__(self, input_size, hidden_size, num_layers, num_classes, sequence_length):\n        \n        super(LSTM, self).__init__()\n        self.num_layers = num_layers\n        self.hidden_size = hidden_size\n        self.sequence_length = sequence_length\n        # rnn layers\n        self.lstm = nn.LSTM(input_size, hidden_size, num_layers)\n        # fully connected layer\n        self.fc = nn.Linear(hidden_size, num_classes)\n        \n    def forward(self, X):\n        \n        #initial hidden states\n        h0 = torch.zeros(self.num_layers, self.sequence_length, self.hidden_size)\n        c0 = torch.zeros(self.num_layers, self.sequence_length, self.hidden_size)\n        # feed into rnn\n        out, _ = self.lstm(X, (h0, c0))\n        \n        # feed into fc\n        # need to decode the hidden state of last time\n        out = out[:, -1, :]\n        out = func.relu(self.fc(out))\n        \n        return func.softmax(out, dim=1)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T04:35:20.052875Z","iopub.execute_input":"2023-11-01T04:35:20.053385Z","iopub.status.idle":"2023-11-01T04:35:20.067395Z","shell.execute_reply.started":"2023-11-01T04:35:20.053325Z","shell.execute_reply":"2023-11-01T04:35:20.066397Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, loaders, loss_func):\n    model.eval()\n    total_loss = 0\n    with torch.no_grad():\n        for _, batch in enumerate(loaders['test']):\n            src, label = batch  # You'll need to adjust this based on your data\n            output = model(src)\n            loss = loss_func(output, label)\n            total_loss += loss.item()\n    return total_loss / len(loaders['test'])","metadata":{"execution":{"iopub.status.busy":"2023-11-01T04:35:20.068611Z","iopub.execute_input":"2023-11-01T04:35:20.069010Z","iopub.status.idle":"2023-11-01T04:35:20.085820Z","shell.execute_reply.started":"2023-11-01T04:35:20.068981Z","shell.execute_reply":"2023-11-01T04:35:20.084501Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_losses = []\nval_losses = []\n\ndef train(model, loss_func, optim, loaders, epochs):\n    \n    for epoch in range(epochs):\n        \n        loss = 0\n        \n        for idx, (data, label) in enumerate(loaders['train']):\n            \n            optim.zero_grad()\n            output = model(data)\n            loss = loss_func(output, label)\n\n            pred_label = (torch.argmax(output,dim =1).view(-1)).numpy()\n            true_label = (torch.argmax(label,dim =1).view(-1)).numpy()\n            acc = accuracy_score(pred_label, true_label)\n\n            loss.backward()\n            optim.step()\n            \n            if (idx%100==0):\n                print(f'epoch: {epoch+1}/{epochs} -> loss: {loss.item()} ; accuracy: {acc}')\n        \n        train_losses.append(loss.item())\n        \n        val_loss = evaluate(model, loaders, loss_func)\n        val_losses.append(val_loss)\n        print(f'epoch: {epoch+1} -> loss: {val_loss}')\n        \n    return train_losses, val_losses","metadata":{"execution":{"iopub.status.busy":"2023-11-01T04:35:20.087158Z","iopub.execute_input":"2023-11-01T04:35:20.087687Z","iopub.status.idle":"2023-11-01T04:35:20.101461Z","shell.execute_reply.started":"2023-11-01T04:35:20.087651Z","shell.execute_reply":"2023-11-01T04:35:20.100239Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model = LSTM(input_size, 500, 2, 10, sequence_length)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T04:35:20.103729Z","iopub.execute_input":"2023-11-01T04:35:20.104615Z","iopub.status.idle":"2023-11-01T04:35:20.175940Z","shell.execute_reply.started":"2023-11-01T04:35:20.104577Z","shell.execute_reply":"2023-11-01T04:35:20.174677Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_losses, val_losses = train(model, criterion, optimizer, loaders, num_epochs)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T04:35:20.177623Z","iopub.execute_input":"2023-11-01T04:35:20.178889Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"epoch: 1/5 -> loss: 2.302506446838379 ; accuracy: 0.0\nepoch: 1/5 -> loss: 2.2993690967559814 ; accuracy: 0.3125\nepoch: 1/5 -> loss: 2.2940189838409424 ; accuracy: 0.21875\nepoch: 1/5 -> loss: 2.293480157852173 ; accuracy: 0.1875\nepoch: 1/5 -> loss: 2.2375707626342773 ; accuracy: 0.25\nepoch: 1/5 -> loss: 2.271878242492676 ; accuracy: 0.125\nepoch: 1 -> loss: 2.228910564437626\nepoch: 2/5 -> loss: 2.2522449493408203 ; accuracy: 0.1875\nepoch: 2/5 -> loss: 2.1463804244995117 ; accuracy: 0.34375\nepoch: 2/5 -> loss: 2.2714409828186035 ; accuracy: 0.21875\nepoch: 2/5 -> loss: 2.2743020057678223 ; accuracy: 0.1875\nepoch: 2/5 -> loss: 2.2256624698638916 ; accuracy: 0.25\nepoch: 2/5 -> loss: 2.2751758098602295 ; accuracy: 0.125\nepoch: 2 -> loss: 2.224353617570532\nepoch: 3/5 -> loss: 2.257131576538086 ; accuracy: 0.1875\nepoch: 3/5 -> loss: 2.1434574127197266 ; accuracy: 0.34375\nepoch: 3/5 -> loss: 2.2672977447509766 ; accuracy: 0.21875\nepoch: 3/5 -> loss: 2.2771358489990234 ; accuracy: 0.1875\nepoch: 3/5 -> loss: 2.2184059619903564 ; accuracy: 0.25\nepoch: 3/5 -> loss: 2.28084659576416 ; accuracy: 0.125\nepoch: 3 -> loss: 2.2229340827371193\nepoch: 4/5 -> loss: 2.259065628051758 ; accuracy: 0.1875\nepoch: 4/5 -> loss: 2.147963047027588 ; accuracy: 0.34375\nepoch: 4/5 -> loss: 2.2617876529693604 ; accuracy: 0.21875\nepoch: 4/5 -> loss: 2.279129981994629 ; accuracy: 0.1875\nepoch: 4/5 -> loss: 2.2153570652008057 ; accuracy: 0.25\n","output_type":"stream"}]},{"cell_type":"code","source":"train_losses","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_losses","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}