{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pickle\nimport joblib\nimport matplotlib.pyplot as plt\nimport librosa, librosa.display\nfrom IPython.display import Audio, FileLink\nfrom pydub import AudioSegment\nimport os\nimport gc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import MaxAbsScaler\n\nfrom tensorflow.keras.layers import Input, Dense, Flatten\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.metrics import Precision, Recall\nfrom tensorflow.keras import regularizers\nfrom tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.activations import softmax\nfrom tensorflow.keras.optimizers import Adam","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-31T18:29:20.878739Z","iopub.execute_input":"2023-10-31T18:29:20.879122Z","iopub.status.idle":"2023-10-31T18:29:24.758944Z","shell.execute_reply.started":"2023-10-31T18:29:20.879088Z","shell.execute_reply":"2023-10-31T18:29:24.758051Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"iemo_data = pd.read_csv('/kaggle/input/iemocap-transcriptions-english-french/iemocapTrans.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:29:24.760710Z","iopub.execute_input":"2023-10-31T18:29:24.761215Z","iopub.status.idle":"2023-10-31T18:29:24.816071Z","shell.execute_reply.started":"2023-10-31T18:29:24.761189Z","shell.execute_reply":"2023-10-31T18:29:24.815105Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"iemo_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:29:24.817149Z","iopub.execute_input":"2023-10-31T18:29:24.817428Z","iopub.status.idle":"2023-10-31T18:29:24.837179Z","shell.execute_reply.started":"2023-10-31T18:29:24.817403Z","shell.execute_reply":"2023-10-31T18:29:24.836094Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                        _id  activation  dominance emotion  end_time  \\\n0  625682441da7a5c1eaef3689         2.5        3.5     sad    6.0541   \n1  625682441da7a5c1eaef368a         3.0        4.0     sad   15.1000   \n2  625682441da7a5c1eaef368b         2.5        4.5     sad   23.3599   \n3  625682441da7a5c1eaef368c         2.5        4.0     sad   26.4151   \n4  625682441da7a5c1eaef368d         3.0        3.5     sad   31.4253   \n\n   start_time                titre  \\\n0      3.9987  Ses02M_impro02_F000   \n1      7.0366  Ses02M_impro02_M000   \n2     15.5524  Ses02M_impro02_F001   \n3     23.5790  Ses02M_impro02_F002   \n4     26.7598  Ses02M_impro02_M001   \n\n                                        to_translate  \\\n0                            I don't want you to go.   \n1   I know, I know. I don't want to go either bab...   \n2   I'm going to miss you too; I don't know what ...   \n3                   I don't want to be a single mom.   \n4   You won't be. I'll be back; I'll be back befo...   \n\n                                          translated  valence  \n0                      Je ne veux pas que tu partes.      2.5  \n1  Je sais je sais. Je ne veux pas y aller non pl...      2.0  \n2  Tu vas me manquer aussi; Je ne sais pas ce que...      1.5  \n3          Je ne veux pas être une mère célibataire.      1.5  \n4  Vous ne le serez pas. Je reviendrai; Je serai ...      3.5  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_id</th>\n      <th>activation</th>\n      <th>dominance</th>\n      <th>emotion</th>\n      <th>end_time</th>\n      <th>start_time</th>\n      <th>titre</th>\n      <th>to_translate</th>\n      <th>translated</th>\n      <th>valence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>625682441da7a5c1eaef3689</td>\n      <td>2.5</td>\n      <td>3.5</td>\n      <td>sad</td>\n      <td>6.0541</td>\n      <td>3.9987</td>\n      <td>Ses02M_impro02_F000</td>\n      <td>I don't want you to go.</td>\n      <td>Je ne veux pas que tu partes.</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>625682441da7a5c1eaef368a</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>sad</td>\n      <td>15.1000</td>\n      <td>7.0366</td>\n      <td>Ses02M_impro02_M000</td>\n      <td>I know, I know. I don't want to go either bab...</td>\n      <td>Je sais je sais. Je ne veux pas y aller non pl...</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>625682441da7a5c1eaef368b</td>\n      <td>2.5</td>\n      <td>4.5</td>\n      <td>sad</td>\n      <td>23.3599</td>\n      <td>15.5524</td>\n      <td>Ses02M_impro02_F001</td>\n      <td>I'm going to miss you too; I don't know what ...</td>\n      <td>Tu vas me manquer aussi; Je ne sais pas ce que...</td>\n      <td>1.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>625682441da7a5c1eaef368c</td>\n      <td>2.5</td>\n      <td>4.0</td>\n      <td>sad</td>\n      <td>26.4151</td>\n      <td>23.5790</td>\n      <td>Ses02M_impro02_F002</td>\n      <td>I don't want to be a single mom.</td>\n      <td>Je ne veux pas être une mère célibataire.</td>\n      <td>1.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>625682441da7a5c1eaef368d</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>sad</td>\n      <td>31.4253</td>\n      <td>26.7598</td>\n      <td>Ses02M_impro02_M001</td>\n      <td>You won't be. I'll be back; I'll be back befo...</td>\n      <td>Vous ne le serez pas. Je reviendrai; Je serai ...</td>\n      <td>3.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"iemo_data = iemo_data[['emotion', 'titre']]\niemo_data['filepath'] = '/kaggle/input/iemocap-transcriptions-english-french/Iemocap_audio/iemocap_audio/IEMOCAP_wav/' + iemo_data['titre'] + '.wav'","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:29:24.839119Z","iopub.execute_input":"2023-10-31T18:29:24.839396Z","iopub.status.idle":"2023-10-31T18:29:24.850835Z","shell.execute_reply.started":"2023-10-31T18:29:24.839372Z","shell.execute_reply":"2023-10-31T18:29:24.849963Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# ravdess dataset\n# emotions -> 01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised\n# third part of the name\n\nemo_dict = {\n    '01': 'neu',\n    '02': 'neu',\n    '03': 'hap',\n    '04': 'sad',\n    '05': 'ang',\n    '06': 'fea',\n    '07': 'dis',\n    '08': 'sur'\n}\n\nravdess_base = \"/kaggle/input/ravdess-emotional-speech-audio/\"\n\nrav_data = pd.DataFrame(columns=['emotion', 'titre', 'filepath'])\n\nfor dirname, _, filenames in os.walk(ravdess_base):\n    for filename in filenames:\n        \n        info_list = filename.split('-')\n        emotion = emo_dict[info_list[2]]\n                \n        new_row = {\n            'emotion': [emotion],\n            'titre': [filename[:-4]],\n            'filepath': [os.path.join(dirname, filename)]\n        }\n        rav_data = pd.concat([rav_data, pd.DataFrame(new_row)], ignore_index=True)\nrav_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:29:24.851955Z","iopub.execute_input":"2023-10-31T18:29:24.852214Z","iopub.status.idle":"2023-10-31T18:29:26.314907Z","shell.execute_reply.started":"2023-10-31T18:29:24.852192Z","shell.execute_reply":"2023-10-31T18:29:26.313915Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"  emotion                 titre  \\\n0     sur  03-01-08-01-01-01-02   \n1     neu  03-01-01-01-01-01-02   \n2     dis  03-01-07-02-01-02-02   \n3     dis  03-01-07-01-01-02-02   \n4     neu  03-01-01-01-02-01-02   \n\n                                            filepath  \n0  /kaggle/input/ravdess-emotional-speech-audio/A...  \n1  /kaggle/input/ravdess-emotional-speech-audio/A...  \n2  /kaggle/input/ravdess-emotional-speech-audio/A...  \n3  /kaggle/input/ravdess-emotional-speech-audio/A...  \n4  /kaggle/input/ravdess-emotional-speech-audio/A...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>emotion</th>\n      <th>titre</th>\n      <th>filepath</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sur</td>\n      <td>03-01-08-01-01-01-02</td>\n      <td>/kaggle/input/ravdess-emotional-speech-audio/A...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>neu</td>\n      <td>03-01-01-01-01-01-02</td>\n      <td>/kaggle/input/ravdess-emotional-speech-audio/A...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>dis</td>\n      <td>03-01-07-02-01-02-02</td>\n      <td>/kaggle/input/ravdess-emotional-speech-audio/A...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>dis</td>\n      <td>03-01-07-01-01-02-02</td>\n      <td>/kaggle/input/ravdess-emotional-speech-audio/A...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>neu</td>\n      <td>03-01-01-01-02-01-02</td>\n      <td>/kaggle/input/ravdess-emotional-speech-audio/A...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# tess dataset\n\ntess_base = \"/kaggle/input/toronto-emotional-speech-set-tess/TESS Toronto emotional speech set data\"\n\ntess_dict = {\n    'neutral': 'neu',\n    'pleasant_surprised': 'sur',\n    'happy': 'hap',\n    'Sad': 'sad',\n    'sad': 'sad',\n    'angry': 'ang',\n    'Fear': 'fea',\n    'fear': 'fea',\n    'disgust': 'dis',\n    'Pleasant_surprise': 'sur'\n}\n\ntess_data = pd.DataFrame(columns=['emotion', 'titre', 'filepath'])\n\nfor dirname, _, filenames in os.walk(tess_base):\n    for filename in filenames:\n        \n        new_row = {\n            'emotion': [tess_dict[dirname.split('/')[-1][4:]]],\n            'titre': [filename[:-4]],\n            'filepath': [os.path.join(dirname, filename)]\n        }\n        tess_data = pd.concat([tess_data, pd.DataFrame(new_row)], ignore_index=True)\n        \ntess_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:29:26.316001Z","iopub.execute_input":"2023-10-31T18:29:26.316268Z","iopub.status.idle":"2023-10-31T18:29:27.673842Z","shell.execute_reply.started":"2023-10-31T18:29:26.316245Z","shell.execute_reply":"2023-10-31T18:29:27.672929Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"  emotion            titre                                           filepath\n0     fea    YAF_home_fear  /kaggle/input/toronto-emotional-speech-set-tes...\n1     fea   YAF_youth_fear  /kaggle/input/toronto-emotional-speech-set-tes...\n2     fea    YAF_near_fear  /kaggle/input/toronto-emotional-speech-set-tes...\n3     fea  YAF_search_fear  /kaggle/input/toronto-emotional-speech-set-tes...\n4     fea    YAF_pick_fear  /kaggle/input/toronto-emotional-speech-set-tes...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>emotion</th>\n      <th>titre</th>\n      <th>filepath</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>fea</td>\n      <td>YAF_home_fear</td>\n      <td>/kaggle/input/toronto-emotional-speech-set-tes...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fea</td>\n      <td>YAF_youth_fear</td>\n      <td>/kaggle/input/toronto-emotional-speech-set-tes...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>fea</td>\n      <td>YAF_near_fear</td>\n      <td>/kaggle/input/toronto-emotional-speech-set-tes...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>fea</td>\n      <td>YAF_search_fear</td>\n      <td>/kaggle/input/toronto-emotional-speech-set-tes...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>fea</td>\n      <td>YAF_pick_fear</td>\n      <td>/kaggle/input/toronto-emotional-speech-set-tes...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data = pd.concat([iemo_data, rav_data, tess_data], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:29:27.675055Z","iopub.execute_input":"2023-10-31T18:29:27.675401Z","iopub.status.idle":"2023-10-31T18:29:27.681360Z","shell.execute_reply.started":"2023-10-31T18:29:27.675372Z","shell.execute_reply":"2023-10-31T18:29:27.680405Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data = data.sample(frac=1)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:29:27.682549Z","iopub.execute_input":"2023-10-31T18:29:27.683146Z","iopub.status.idle":"2023-10-31T18:29:27.694887Z","shell.execute_reply.started":"2023-10-31T18:29:27.683122Z","shell.execute_reply":"2023-10-31T18:29:27.694108Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def show_cat(df):\n    print('sad', df.emotion.loc[df.emotion == 'sad'].count())\n    print('fru', df.emotion.loc[df.emotion == 'fru'].count())\n    print('neu', df.emotion.loc[df.emotion == 'neu'].count())\n    print('hap', df.emotion.loc[df.emotion == 'hap'].count())\n    print('exc', df.emotion.loc[df.emotion == 'exc'].count())\n    print('sur', df.emotion.loc[df.emotion == 'sur'].count())\n    print('ang', df.emotion.loc[df.emotion == 'ang'].count())\n    print('fea', df.emotion.loc[df.emotion == 'fea'].count())\n    print('oth', df.emotion.loc[df.emotion == 'oth'].count())\n    print('dis', df.emotion.loc[df.emotion == 'dis'].count())\n    \nshow_cat(data)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:29:27.696061Z","iopub.execute_input":"2023-10-31T18:29:27.696730Z","iopub.status.idle":"2023-10-31T18:29:27.737321Z","shell.execute_reply.started":"2023-10-31T18:29:27.696697Z","shell.execute_reply":"2023-10-31T18:29:27.736451Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"sad 2034\nfru 2917\nneu 2702\nhap 1440\nexc 1976\nsur 894\nang 2053\nfea 891\noth 26\ndis 786\n","output_type":"stream"}]},{"cell_type":"code","source":"data = pd.get_dummies(data, columns=['emotion'], dtype='int')\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:29:27.740349Z","iopub.execute_input":"2023-10-31T18:29:27.740627Z","iopub.status.idle":"2023-10-31T18:29:27.759182Z","shell.execute_reply.started":"2023-10-31T18:29:27.740600Z","shell.execute_reply":"2023-10-31T18:29:27.758343Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                        titre  \\\n4728   Ses05F_script01_1_M027   \n7640      Ses04M_impro08_M025   \n4926      Ses02M_impro06_F014   \n10589    03-01-04-01-01-02-15   \n9868      Ses03F_impro07_M024   \n\n                                                filepath  emotion_ang  \\\n4728   /kaggle/input/iemocap-transcriptions-english-f...            0   \n7640   /kaggle/input/iemocap-transcriptions-english-f...            0   \n4926   /kaggle/input/iemocap-transcriptions-english-f...            0   \n10589  /kaggle/input/ravdess-emotional-speech-audio/A...            0   \n9868   /kaggle/input/iemocap-transcriptions-english-f...            0   \n\n       emotion_dis  emotion_exc  emotion_fea  emotion_fru  emotion_hap  \\\n4728             0            0            0            1            0   \n7640             0            0            0            0            0   \n4926             0            0            0            0            0   \n10589            0            0            0            0            0   \n9868             0            1            0            0            0   \n\n       emotion_neu  emotion_oth  emotion_sad  emotion_sur  \n4728             0            0            0            0  \n7640             1            0            0            0  \n4926             0            0            1            0  \n10589            0            0            1            0  \n9868             0            0            0            0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>titre</th>\n      <th>filepath</th>\n      <th>emotion_ang</th>\n      <th>emotion_dis</th>\n      <th>emotion_exc</th>\n      <th>emotion_fea</th>\n      <th>emotion_fru</th>\n      <th>emotion_hap</th>\n      <th>emotion_neu</th>\n      <th>emotion_oth</th>\n      <th>emotion_sad</th>\n      <th>emotion_sur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4728</th>\n      <td>Ses05F_script01_1_M027</td>\n      <td>/kaggle/input/iemocap-transcriptions-english-f...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7640</th>\n      <td>Ses04M_impro08_M025</td>\n      <td>/kaggle/input/iemocap-transcriptions-english-f...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4926</th>\n      <td>Ses02M_impro06_F014</td>\n      <td>/kaggle/input/iemocap-transcriptions-english-f...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10589</th>\n      <td>03-01-04-01-01-02-15</td>\n      <td>/kaggle/input/ravdess-emotional-speech-audio/A...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9868</th>\n      <td>Ses03F_impro07_M024</td>\n      <td>/kaggle/input/iemocap-transcriptions-english-f...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def add_noise(data, noise_factor):\n    noise = np.random.randn(len(data))\n    noice_data = data + noise_factor * noise\n    noice_data = noice_data.astype(type(data[0]))\n    return noice_data\n\ndef change_pitch(data, sampling_rate, n_steps=3):\n    return librosa.effects.pitch_shift(data, sr=sampling_rate, n_steps=n_steps)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:29:27.760059Z","iopub.execute_input":"2023-10-31T18:29:27.760337Z","iopub.status.idle":"2023-10-31T18:29:27.766024Z","shell.execute_reply.started":"2023-10-31T18:29:27.760313Z","shell.execute_reply":"2023-10-31T18:29:27.765085Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def audio_to_stft(filepath, emotions, sample_rate):\n    \n    arr_len = 3*sample_rate\n    arr, sr = librosa.load(filepath, sr=sample_rate)\n    \n    audios = []\n    \n    while (arr.shape[0] >= sample_rate):\n        \n        if arr.shape[0] < arr_len:\n            \n            arr = np.pad(arr, (0, arr_len-arr.shape[0]), 'constant')\n            \n#             if ((emotions['emotion_sur'] == 1) | (emotions['emotion_fea'] == 1) | (emotions['emotion_dis'] == 1)):\n    #                 # create noice audio\n    #                 noise_audio = add_noise(arr, 0.0001)\n    #                 audios.append(librosa.amplitude_to_db(np.abs(librosa.core.stft(noise_audio, n_fft=1024, hop_length=512))))\n#                 # change pitch of audio\n#                 pitch_audio = change_pitch(arr, sr)\n#                 audios.append(librosa.amplitude_to_db(np.abs(librosa.core.stft(pitch_audio, n_fft=1024, hop_length=512))))\n            audios.append(librosa.amplitude_to_db(np.abs(librosa.core.stft(arr, n_fft=1024, hop_length=512))))\n            arr = np.zeros(0)\n\n        else:\n                    \n            seg = arr[:arr_len]\n#             if ((emotions['emotion_sur'] == 1) | (emotions['emotion_fea'] == 1) | (emotions['emotion_dis'] == 1)):\n#                 # create noice audio\n#                 noise_audio = add_noise(seg, 0.0001)\n#                 audios.append(librosa.amplitude_to_db(np.abs(librosa.core.stft(noise_audio, n_fft=1024, hop_length=512))))\n#                 # change pitch of audio\n#                 pitch_audio = change_pitch(seg, sr)\n#                 audios.append(librosa.amplitude_to_db(np.abs(librosa.core.stft(pitch_audio, n_fft=1024, hop_length=512))))\n            audios.append(librosa.amplitude_to_db(np.abs(librosa.core.stft(seg, n_fft=1024, hop_length=512))))\n            arr = arr[arr_len:]\n            \n    return audios","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:29:27.767338Z","iopub.execute_input":"2023-10-31T18:29:27.767653Z","iopub.status.idle":"2023-10-31T18:29:27.778377Z","shell.execute_reply.started":"2023-10-31T18:29:27.767616Z","shell.execute_reply":"2023-10-31T18:29:27.777620Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"X = []\ny = []\n\nfor _, row in data.iterrows():\n\n    audios = audio_to_stft(row['filepath'], row.drop(['filepath', 'titre']), 22500)\n    \n    for audio in audios:\n        \n        # adding normal audio\n        X.append(audio.reshape(171, -1, 3))\n        y.append(row.drop(['filepath', 'titre']))","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:29:27.779430Z","iopub.execute_input":"2023-10-31T18:29:27.779697Z","iopub.status.idle":"2023-10-31T18:34:36.836372Z","shell.execute_reply.started":"2023-10-31T18:29:27.779675Z","shell.execute_reply":"2023-10-31T18:34:36.835310Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"del data, iemo_data, rav_data, tess_data\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:34:36.837811Z","iopub.execute_input":"2023-10-31T18:34:36.838910Z","iopub.status.idle":"2023-10-31T18:34:37.153731Z","shell.execute_reply.started":"2023-10-31T18:34:36.838871Z","shell.execute_reply":"2023-10-31T18:34:37.152775Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"max = 0\nfor x in X:\n    max1 = np.max(np.abs(x))\n    if max < max1:\n        max = max1","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:34:37.155235Z","iopub.execute_input":"2023-10-31T18:34:37.155650Z","iopub.status.idle":"2023-10-31T18:34:38.174875Z","shell.execute_reply.started":"2023-10-31T18:34:37.155599Z","shell.execute_reply":"2023-10-31T18:34:38.173825Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"X_np = np.array(X, dtype=np.float16) / max\ny_np = np.array(y, dtype=np.float16)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:34:38.176213Z","iopub.execute_input":"2023-10-31T18:34:38.176513Z","iopub.status.idle":"2023-10-31T18:35:04.111386Z","shell.execute_reply.started":"2023-10-31T18:34:38.176488Z","shell.execute_reply":"2023-10-31T18:35:04.110552Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"SPEC_SHAPE = X_np.shape[1:-1]\nSPEC_SHAPE","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:35:04.113265Z","iopub.execute_input":"2023-10-31T18:35:04.113554Z","iopub.status.idle":"2023-10-31T18:35:04.119625Z","shell.execute_reply.started":"2023-10-31T18:35:04.113528Z","shell.execute_reply":"2023-10-31T18:35:04.118736Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(171, 132)"},"metadata":{}}]},{"cell_type":"code","source":"size = X_np.shape[0]","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:35:04.120764Z","iopub.execute_input":"2023-10-31T18:35:04.121100Z","iopub.status.idle":"2023-10-31T18:35:04.132997Z","shell.execute_reply.started":"2023-10-31T18:35:04.121068Z","shell.execute_reply":"2023-10-31T18:35:04.132205Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"X_train = np.copy(X_np[:int(size*0.9)])\ny_train = np.copy(y_np[:int(size*0.9)])\nX_test = np.copy(X_np[int(size*0.9):])\ny_test = np.copy(y_np[int(size*0.9):])","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:35:04.134186Z","iopub.execute_input":"2023-10-31T18:35:04.134498Z","iopub.status.idle":"2023-10-31T18:35:05.206840Z","shell.execute_reply.started":"2023-10-31T18:35:04.134469Z","shell.execute_reply":"2023-10-31T18:35:05.205793Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del X_np\ndel y_np\ndel X\ndel y\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:35:05.208067Z","iopub.execute_input":"2023-10-31T18:35:05.208327Z","iopub.status.idle":"2023-10-31T18:35:05.506370Z","shell.execute_reply.started":"2023-10-31T18:35:05.208304Z","shell.execute_reply":"2023-10-31T18:35:05.505494Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"# Xtr, Xte, ytr, yte = train_test_split(X_np, y_np, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:35:05.507627Z","iopub.execute_input":"2023-10-31T18:35:05.508468Z","iopub.status.idle":"2023-10-31T18:35:05.517761Z","shell.execute_reply.started":"2023-10-31T18:35:05.508435Z","shell.execute_reply":"2023-10-31T18:35:05.517008Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"resnet50 = VGG19(\n    include_top = False, \n    weights = 'imagenet',\n    input_shape=SPEC_SHAPE + (3,),\n)\n\n# freeze layers\nfor layer in resnet50.layers:\n    layer.trainable = False\n    \nx = Flatten()(resnet50.output)\npred_layer = Dense(10, activation='sigmoid')(x)\n\nmodel = Model(inputs=resnet50.input, outputs=pred_layer)\nmodel.summary()\n        ","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:35:05.518910Z","iopub.execute_input":"2023-10-31T18:35:05.519248Z","iopub.status.idle":"2023-10-31T18:35:09.213309Z","shell.execute_reply.started":"2023-10-31T18:35:05.519217Z","shell.execute_reply":"2023-10-31T18:35:09.212357Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n80134624/80134624 [==============================] - 0s 0us/step\nModel: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 171, 132, 3)]     0         \n                                                                 \n block1_conv1 (Conv2D)       (None, 171, 132, 64)      1792      \n                                                                 \n block1_conv2 (Conv2D)       (None, 171, 132, 64)      36928     \n                                                                 \n block1_pool (MaxPooling2D)  (None, 85, 66, 64)        0         \n                                                                 \n block2_conv1 (Conv2D)       (None, 85, 66, 128)       73856     \n                                                                 \n block2_conv2 (Conv2D)       (None, 85, 66, 128)       147584    \n                                                                 \n block2_pool (MaxPooling2D)  (None, 42, 33, 128)       0         \n                                                                 \n block3_conv1 (Conv2D)       (None, 42, 33, 256)       295168    \n                                                                 \n block3_conv2 (Conv2D)       (None, 42, 33, 256)       590080    \n                                                                 \n block3_conv3 (Conv2D)       (None, 42, 33, 256)       590080    \n                                                                 \n block3_conv4 (Conv2D)       (None, 42, 33, 256)       590080    \n                                                                 \n block3_pool (MaxPooling2D)  (None, 21, 16, 256)       0         \n                                                                 \n block4_conv1 (Conv2D)       (None, 21, 16, 512)       1180160   \n                                                                 \n block4_conv2 (Conv2D)       (None, 21, 16, 512)       2359808   \n                                                                 \n block4_conv3 (Conv2D)       (None, 21, 16, 512)       2359808   \n                                                                 \n block4_conv4 (Conv2D)       (None, 21, 16, 512)       2359808   \n                                                                 \n block4_pool (MaxPooling2D)  (None, 10, 8, 512)        0         \n                                                                 \n block5_conv1 (Conv2D)       (None, 10, 8, 512)        2359808   \n                                                                 \n block5_conv2 (Conv2D)       (None, 10, 8, 512)        2359808   \n                                                                 \n block5_conv3 (Conv2D)       (None, 10, 8, 512)        2359808   \n                                                                 \n block5_conv4 (Conv2D)       (None, 10, 8, 512)        2359808   \n                                                                 \n block5_pool (MaxPooling2D)  (None, 5, 4, 512)         0         \n                                                                 \n flatten (Flatten)           (None, 10240)             0         \n                                                                 \n dense (Dense)               (None, 10)                102410    \n                                                                 \n=================================================================\nTotal params: 20,126,794\nTrainable params: 102,410\nNon-trainable params: 20,024,384\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(\n    loss='categorical_crossentropy',\n    optimizer=Adam(learning_rate=1e-3),\n    metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:35:09.214542Z","iopub.execute_input":"2023-10-31T18:35:09.214883Z","iopub.status.idle":"2023-10-31T18:35:09.236451Z","shell.execute_reply.started":"2023-10-31T18:35:09.214858Z","shell.execute_reply":"2023-10-31T18:35:09.235545Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# early_stopper = EarlyStopping(monitor = 'val_loss', patience = 3)\n# model_save = ModelCheckpoint(filepath='models/', monitor='val_losss')","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:35:09.237712Z","iopub.execute_input":"2023-10-31T18:35:09.237979Z","iopub.status.idle":"2023-10-31T18:35:09.242085Z","shell.execute_reply.started":"2023-10-31T18:35:09.237956Z","shell.execute_reply":"2023-10-31T18:35:09.241254Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"fit_history = model.fit(X_train, y_train, epochs=6, validation_data=(X_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:35:09.243312Z","iopub.execute_input":"2023-10-31T18:35:09.244034Z","iopub.status.idle":"2023-10-31T18:38:32.881984Z","shell.execute_reply.started":"2023-10-31T18:35:09.244001Z","shell.execute_reply":"2023-10-31T18:38:32.881145Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Epoch 1/6\n648/648 [==============================] - 40s 50ms/step - loss: 1.6099 - accuracy: 0.3825 - val_loss: 1.3965 - val_accuracy: 0.4707\nEpoch 2/6\n648/648 [==============================] - 30s 46ms/step - loss: 1.4617 - accuracy: 0.4429 - val_loss: 1.3749 - val_accuracy: 0.4855\nEpoch 3/6\n648/648 [==============================] - 30s 46ms/step - loss: 1.4009 - accuracy: 0.4590 - val_loss: 1.3505 - val_accuracy: 0.4707\nEpoch 4/6\n648/648 [==============================] - 30s 46ms/step - loss: 1.3614 - accuracy: 0.4800 - val_loss: 1.3509 - val_accuracy: 0.4941\nEpoch 5/6\n648/648 [==============================] - 30s 46ms/step - loss: 1.3259 - accuracy: 0.4928 - val_loss: 1.3383 - val_accuracy: 0.5002\nEpoch 6/6\n648/648 [==============================] - 30s 46ms/step - loss: 1.2927 - accuracy: 0.5025 - val_loss: 1.3439 - val_accuracy: 0.4889\n","output_type":"stream"}]},{"cell_type":"code","source":"name = 'modelvgg19-without-noice-50-48'","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:39:33.430380Z","iopub.execute_input":"2023-10-31T18:39:33.430779Z","iopub.status.idle":"2023-10-31T18:39:33.435555Z","shell.execute_reply.started":"2023-10-31T18:39:33.430748Z","shell.execute_reply":"2023-10-31T18:39:33.434439Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"model.save(f'{name}.h5') # 0.44 -> 0.40\njoblib.dump(model, f'{name}.pkl')","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:39:33.819977Z","iopub.execute_input":"2023-10-31T18:39:33.820685Z","iopub.status.idle":"2023-10-31T18:39:34.360130Z","shell.execute_reply.started":"2023-10-31T18:39:33.820655Z","shell.execute_reply":"2023-10-31T18:39:34.359205Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"['modelvgg19-without-noice-50-48.pkl']"},"metadata":{}}]},{"cell_type":"code","source":"FileLink(f'{name}.h5')","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:39:34.760273Z","iopub.execute_input":"2023-10-31T18:39:34.760951Z","iopub.status.idle":"2023-10-31T18:39:34.767107Z","shell.execute_reply.started":"2023-10-31T18:39:34.760914Z","shell.execute_reply":"2023-10-31T18:39:34.766231Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/modelvgg19-without-noice-50-48.h5","text/html":"<a href='modelvgg19-without-noice-50-48.h5' target='_blank'>modelvgg19-without-noice-50-48.h5</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"FileLink(f'{name}.pkl')","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:39:35.299762Z","iopub.execute_input":"2023-10-31T18:39:35.300441Z","iopub.status.idle":"2023-10-31T18:39:35.306194Z","shell.execute_reply.started":"2023-10-31T18:39:35.300409Z","shell.execute_reply":"2023-10-31T18:39:35.305285Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/modelvgg19-without-noice-50-48.pkl","text/html":"<a href='modelvgg19-without-noice-50-48.pkl' target='_blank'>modelvgg19-without-noice-50-48.pkl</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}