{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pickle\nimport joblib\nimport matplotlib.pyplot as plt\nimport librosa, librosa.display\nfrom IPython.display import Audio, FileLink\nfrom pydub import AudioSegment\nimport os\nimport gc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import MaxAbsScaler\n\nfrom tensorflow.keras.layers import Input, Dense, Flatten\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.metrics import Precision, Recall\nfrom tensorflow.keras import regularizers\nfrom tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.activations import softmax\nfrom tensorflow.keras.optimizers import Adam","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-31T18:42:16.562344Z","iopub.execute_input":"2023-10-31T18:42:16.562771Z","iopub.status.idle":"2023-10-31T18:42:21.343073Z","shell.execute_reply.started":"2023-10-31T18:42:16.562731Z","shell.execute_reply":"2023-10-31T18:42:21.342250Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"iemo_data = pd.read_csv('/kaggle/input/iemocap-transcriptions-english-french/iemocapTrans.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:42:21.347931Z","iopub.execute_input":"2023-10-31T18:42:21.348195Z","iopub.status.idle":"2023-10-31T18:42:21.401044Z","shell.execute_reply.started":"2023-10-31T18:42:21.348170Z","shell.execute_reply":"2023-10-31T18:42:21.400332Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"iemo_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:42:21.402442Z","iopub.execute_input":"2023-10-31T18:42:21.402790Z","iopub.status.idle":"2023-10-31T18:42:21.422115Z","shell.execute_reply.started":"2023-10-31T18:42:21.402759Z","shell.execute_reply":"2023-10-31T18:42:21.421229Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                        _id  activation  dominance emotion  end_time  \\\n0  625682441da7a5c1eaef3689         2.5        3.5     sad    6.0541   \n1  625682441da7a5c1eaef368a         3.0        4.0     sad   15.1000   \n2  625682441da7a5c1eaef368b         2.5        4.5     sad   23.3599   \n3  625682441da7a5c1eaef368c         2.5        4.0     sad   26.4151   \n4  625682441da7a5c1eaef368d         3.0        3.5     sad   31.4253   \n\n   start_time                titre  \\\n0      3.9987  Ses02M_impro02_F000   \n1      7.0366  Ses02M_impro02_M000   \n2     15.5524  Ses02M_impro02_F001   \n3     23.5790  Ses02M_impro02_F002   \n4     26.7598  Ses02M_impro02_M001   \n\n                                        to_translate  \\\n0                            I don't want you to go.   \n1   I know, I know. I don't want to go either bab...   \n2   I'm going to miss you too; I don't know what ...   \n3                   I don't want to be a single mom.   \n4   You won't be. I'll be back; I'll be back befo...   \n\n                                          translated  valence  \n0                      Je ne veux pas que tu partes.      2.5  \n1  Je sais je sais. Je ne veux pas y aller non pl...      2.0  \n2  Tu vas me manquer aussi; Je ne sais pas ce que...      1.5  \n3          Je ne veux pas être une mère célibataire.      1.5  \n4  Vous ne le serez pas. Je reviendrai; Je serai ...      3.5  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_id</th>\n      <th>activation</th>\n      <th>dominance</th>\n      <th>emotion</th>\n      <th>end_time</th>\n      <th>start_time</th>\n      <th>titre</th>\n      <th>to_translate</th>\n      <th>translated</th>\n      <th>valence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>625682441da7a5c1eaef3689</td>\n      <td>2.5</td>\n      <td>3.5</td>\n      <td>sad</td>\n      <td>6.0541</td>\n      <td>3.9987</td>\n      <td>Ses02M_impro02_F000</td>\n      <td>I don't want you to go.</td>\n      <td>Je ne veux pas que tu partes.</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>625682441da7a5c1eaef368a</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>sad</td>\n      <td>15.1000</td>\n      <td>7.0366</td>\n      <td>Ses02M_impro02_M000</td>\n      <td>I know, I know. I don't want to go either bab...</td>\n      <td>Je sais je sais. Je ne veux pas y aller non pl...</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>625682441da7a5c1eaef368b</td>\n      <td>2.5</td>\n      <td>4.5</td>\n      <td>sad</td>\n      <td>23.3599</td>\n      <td>15.5524</td>\n      <td>Ses02M_impro02_F001</td>\n      <td>I'm going to miss you too; I don't know what ...</td>\n      <td>Tu vas me manquer aussi; Je ne sais pas ce que...</td>\n      <td>1.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>625682441da7a5c1eaef368c</td>\n      <td>2.5</td>\n      <td>4.0</td>\n      <td>sad</td>\n      <td>26.4151</td>\n      <td>23.5790</td>\n      <td>Ses02M_impro02_F002</td>\n      <td>I don't want to be a single mom.</td>\n      <td>Je ne veux pas être une mère célibataire.</td>\n      <td>1.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>625682441da7a5c1eaef368d</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>sad</td>\n      <td>31.4253</td>\n      <td>26.7598</td>\n      <td>Ses02M_impro02_M001</td>\n      <td>You won't be. I'll be back; I'll be back befo...</td>\n      <td>Vous ne le serez pas. Je reviendrai; Je serai ...</td>\n      <td>3.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"iemo_data = iemo_data[['emotion', 'titre']]\niemo_data['filepath'] = '/kaggle/input/iemocap-transcriptions-english-french/Iemocap_audio/iemocap_audio/IEMOCAP_wav/' + iemo_data['titre'] + '.wav'","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:42:21.424523Z","iopub.execute_input":"2023-10-31T18:42:21.424832Z","iopub.status.idle":"2023-10-31T18:42:21.435541Z","shell.execute_reply.started":"2023-10-31T18:42:21.424808Z","shell.execute_reply":"2023-10-31T18:42:21.434568Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# ravdess dataset\n# emotions -> 01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised\n# third part of the name\n\nemo_dict = {\n    '01': 'neu',\n    '02': 'neu',\n    '03': 'hap',\n    '04': 'sad',\n    '05': 'ang',\n    '06': 'fea',\n    '07': 'dis',\n    '08': 'sur'\n}\n\nravdess_base = \"/kaggle/input/ravdess-emotional-speech-audio/\"\n\nrav_data = pd.DataFrame(columns=['emotion', 'titre', 'filepath'])\n\nfor dirname, _, filenames in os.walk(ravdess_base):\n    for filename in filenames:\n        \n        info_list = filename.split('-')\n        emotion = emo_dict[info_list[2]]\n                \n        new_row = {\n            'emotion': [emotion],\n            'titre': [filename[:-4]],\n            'filepath': [os.path.join(dirname, filename)]\n        }\n        rav_data = pd.concat([rav_data, pd.DataFrame(new_row)], ignore_index=True)\nrav_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:42:21.436638Z","iopub.execute_input":"2023-10-31T18:42:21.436895Z","iopub.status.idle":"2023-10-31T18:42:22.892670Z","shell.execute_reply.started":"2023-10-31T18:42:21.436872Z","shell.execute_reply":"2023-10-31T18:42:22.891599Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"  emotion                 titre  \\\n0     sur  03-01-08-01-01-01-02   \n1     neu  03-01-01-01-01-01-02   \n2     dis  03-01-07-02-01-02-02   \n3     dis  03-01-07-01-01-02-02   \n4     neu  03-01-01-01-02-01-02   \n\n                                            filepath  \n0  /kaggle/input/ravdess-emotional-speech-audio/A...  \n1  /kaggle/input/ravdess-emotional-speech-audio/A...  \n2  /kaggle/input/ravdess-emotional-speech-audio/A...  \n3  /kaggle/input/ravdess-emotional-speech-audio/A...  \n4  /kaggle/input/ravdess-emotional-speech-audio/A...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>emotion</th>\n      <th>titre</th>\n      <th>filepath</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sur</td>\n      <td>03-01-08-01-01-01-02</td>\n      <td>/kaggle/input/ravdess-emotional-speech-audio/A...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>neu</td>\n      <td>03-01-01-01-01-01-02</td>\n      <td>/kaggle/input/ravdess-emotional-speech-audio/A...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>dis</td>\n      <td>03-01-07-02-01-02-02</td>\n      <td>/kaggle/input/ravdess-emotional-speech-audio/A...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>dis</td>\n      <td>03-01-07-01-01-02-02</td>\n      <td>/kaggle/input/ravdess-emotional-speech-audio/A...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>neu</td>\n      <td>03-01-01-01-02-01-02</td>\n      <td>/kaggle/input/ravdess-emotional-speech-audio/A...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# tess dataset\n\ntess_base = \"/kaggle/input/toronto-emotional-speech-set-tess/TESS Toronto emotional speech set data\"\n\ntess_dict = {\n    'neutral': 'neu',\n    'pleasant_surprised': 'sur',\n    'happy': 'hap',\n    'Sad': 'sad',\n    'sad': 'sad',\n    'angry': 'ang',\n    'Fear': 'fea',\n    'fear': 'fea',\n    'disgust': 'dis',\n    'Pleasant_surprise': 'sur'\n}\n\ntess_data = pd.DataFrame(columns=['emotion', 'titre', 'filepath'])\n\nfor dirname, _, filenames in os.walk(tess_base):\n    for filename in filenames:\n        \n        new_row = {\n            'emotion': [tess_dict[dirname.split('/')[-1][4:]]],\n            'titre': [filename[:-4]],\n            'filepath': [os.path.join(dirname, filename)]\n        }\n        tess_data = pd.concat([tess_data, pd.DataFrame(new_row)], ignore_index=True)\n        \ntess_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:42:22.893787Z","iopub.execute_input":"2023-10-31T18:42:22.894082Z","iopub.status.idle":"2023-10-31T18:42:24.292646Z","shell.execute_reply.started":"2023-10-31T18:42:22.894057Z","shell.execute_reply":"2023-10-31T18:42:24.291630Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"  emotion            titre                                           filepath\n0     fea    YAF_home_fear  /kaggle/input/toronto-emotional-speech-set-tes...\n1     fea   YAF_youth_fear  /kaggle/input/toronto-emotional-speech-set-tes...\n2     fea    YAF_near_fear  /kaggle/input/toronto-emotional-speech-set-tes...\n3     fea  YAF_search_fear  /kaggle/input/toronto-emotional-speech-set-tes...\n4     fea    YAF_pick_fear  /kaggle/input/toronto-emotional-speech-set-tes...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>emotion</th>\n      <th>titre</th>\n      <th>filepath</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>fea</td>\n      <td>YAF_home_fear</td>\n      <td>/kaggle/input/toronto-emotional-speech-set-tes...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>fea</td>\n      <td>YAF_youth_fear</td>\n      <td>/kaggle/input/toronto-emotional-speech-set-tes...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>fea</td>\n      <td>YAF_near_fear</td>\n      <td>/kaggle/input/toronto-emotional-speech-set-tes...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>fea</td>\n      <td>YAF_search_fear</td>\n      <td>/kaggle/input/toronto-emotional-speech-set-tes...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>fea</td>\n      <td>YAF_pick_fear</td>\n      <td>/kaggle/input/toronto-emotional-speech-set-tes...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data = pd.concat([iemo_data, rav_data, tess_data], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:42:24.294015Z","iopub.execute_input":"2023-10-31T18:42:24.294387Z","iopub.status.idle":"2023-10-31T18:42:24.301227Z","shell.execute_reply.started":"2023-10-31T18:42:24.294354Z","shell.execute_reply":"2023-10-31T18:42:24.300249Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data = data.sample(frac=1)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:42:24.302709Z","iopub.execute_input":"2023-10-31T18:42:24.303024Z","iopub.status.idle":"2023-10-31T18:42:24.317505Z","shell.execute_reply.started":"2023-10-31T18:42:24.302996Z","shell.execute_reply":"2023-10-31T18:42:24.316532Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def show_cat(df):\n    print('sad', df.emotion.loc[df.emotion == 'sad'].count())\n    print('fru', df.emotion.loc[df.emotion == 'fru'].count())\n    print('neu', df.emotion.loc[df.emotion == 'neu'].count())\n    print('hap', df.emotion.loc[df.emotion == 'hap'].count())\n    print('exc', df.emotion.loc[df.emotion == 'exc'].count())\n    print('sur', df.emotion.loc[df.emotion == 'sur'].count())\n    print('ang', df.emotion.loc[df.emotion == 'ang'].count())\n    print('fea', df.emotion.loc[df.emotion == 'fea'].count())\n    print('oth', df.emotion.loc[df.emotion == 'oth'].count())\n    print('dis', df.emotion.loc[df.emotion == 'dis'].count())\n    \nshow_cat(data)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:42:24.318557Z","iopub.execute_input":"2023-10-31T18:42:24.319648Z","iopub.status.idle":"2023-10-31T18:42:24.362353Z","shell.execute_reply.started":"2023-10-31T18:42:24.319597Z","shell.execute_reply":"2023-10-31T18:42:24.361430Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"sad 2034\nfru 2917\nneu 2702\nhap 1440\nexc 1976\nsur 894\nang 2053\nfea 891\noth 26\ndis 786\n","output_type":"stream"}]},{"cell_type":"code","source":"data = pd.get_dummies(data, columns=['emotion'], dtype='int')\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:42:24.363811Z","iopub.execute_input":"2023-10-31T18:42:24.364085Z","iopub.status.idle":"2023-10-31T18:42:24.386937Z","shell.execute_reply.started":"2023-10-31T18:42:24.364061Z","shell.execute_reply":"2023-10-31T18:42:24.385968Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                        titre  \\\n6229   Ses04F_script03_1_M024   \n13847         OAF_nag_neutral   \n15248          OAF_back_happy   \n4600   Ses03F_script03_2_F007   \n12390    03-01-03-02-01-02-03   \n\n                                                filepath  emotion_ang  \\\n6229   /kaggle/input/iemocap-transcriptions-english-f...            0   \n13847  /kaggle/input/toronto-emotional-speech-set-tes...            0   \n15248  /kaggle/input/toronto-emotional-speech-set-tes...            0   \n4600   /kaggle/input/iemocap-transcriptions-english-f...            0   \n12390  /kaggle/input/ravdess-emotional-speech-audio/a...            0   \n\n       emotion_dis  emotion_exc  emotion_fea  emotion_fru  emotion_hap  \\\n6229             0            1            0            0            0   \n13847            0            0            0            0            0   \n15248            0            0            0            0            1   \n4600             0            0            0            1            0   \n12390            0            0            0            0            1   \n\n       emotion_neu  emotion_oth  emotion_sad  emotion_sur  \n6229             0            0            0            0  \n13847            1            0            0            0  \n15248            0            0            0            0  \n4600             0            0            0            0  \n12390            0            0            0            0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>titre</th>\n      <th>filepath</th>\n      <th>emotion_ang</th>\n      <th>emotion_dis</th>\n      <th>emotion_exc</th>\n      <th>emotion_fea</th>\n      <th>emotion_fru</th>\n      <th>emotion_hap</th>\n      <th>emotion_neu</th>\n      <th>emotion_oth</th>\n      <th>emotion_sad</th>\n      <th>emotion_sur</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6229</th>\n      <td>Ses04F_script03_1_M024</td>\n      <td>/kaggle/input/iemocap-transcriptions-english-f...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13847</th>\n      <td>OAF_nag_neutral</td>\n      <td>/kaggle/input/toronto-emotional-speech-set-tes...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15248</th>\n      <td>OAF_back_happy</td>\n      <td>/kaggle/input/toronto-emotional-speech-set-tes...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4600</th>\n      <td>Ses03F_script03_2_F007</td>\n      <td>/kaggle/input/iemocap-transcriptions-english-f...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12390</th>\n      <td>03-01-03-02-01-02-03</td>\n      <td>/kaggle/input/ravdess-emotional-speech-audio/a...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def add_noise(data, noise_factor):\n    noise = np.random.randn(len(data))\n    noice_data = data + noise_factor * noise\n    noice_data = noice_data.astype(type(data[0]))\n    return noice_data\n\ndef change_pitch(data, sampling_rate, n_steps=3):\n    return librosa.effects.pitch_shift(data, sr=sampling_rate, n_steps=n_steps)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:42:24.388138Z","iopub.execute_input":"2023-10-31T18:42:24.388402Z","iopub.status.idle":"2023-10-31T18:42:24.394467Z","shell.execute_reply.started":"2023-10-31T18:42:24.388379Z","shell.execute_reply":"2023-10-31T18:42:24.393520Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def audio_to_stft(filepath, emotions, sample_rate):\n    \n    arr_len = 3*sample_rate\n    arr, sr = librosa.load(filepath, sr=sample_rate)\n    \n    audios = []\n    \n    while (arr.shape[0] >= sample_rate):\n        \n        if arr.shape[0] < arr_len:\n            \n            arr = np.pad(arr, (0, arr_len-arr.shape[0]), 'constant')\n            \n#             if ((emotions['emotion_sur'] == 1) | (emotions['emotion_fea'] == 1) | (emotions['emotion_dis'] == 1)):\n    #                 # create noice audio\n    #                 noise_audio = add_noise(arr, 0.0001)\n    #                 audios.append(librosa.amplitude_to_db(np.abs(librosa.core.stft(noise_audio, n_fft=1024, hop_length=512))))\n#                 # change pitch of audio\n#                 pitch_audio = change_pitch(arr, sr)\n#                 audios.append(librosa.amplitude_to_db(np.abs(librosa.core.stft(pitch_audio, n_fft=1024, hop_length=512))))\n            audios.append(librosa.amplitude_to_db(np.abs(librosa.core.stft(arr, n_fft=1024, hop_length=512))))\n            arr = np.zeros(0)\n\n        else:\n                    \n            seg = arr[:arr_len]\n#             if ((emotions['emotion_sur'] == 1) | (emotions['emotion_fea'] == 1) | (emotions['emotion_dis'] == 1)):\n#                 # create noice audio\n#                 noise_audio = add_noise(seg, 0.0001)\n#                 audios.append(librosa.amplitude_to_db(np.abs(librosa.core.stft(noise_audio, n_fft=1024, hop_length=512))))\n#                 # change pitch of audio\n#                 pitch_audio = change_pitch(seg, sr)\n#                 audios.append(librosa.amplitude_to_db(np.abs(librosa.core.stft(pitch_audio, n_fft=1024, hop_length=512))))\n            audios.append(librosa.amplitude_to_db(np.abs(librosa.core.stft(seg, n_fft=1024, hop_length=512))))\n            arr = arr[arr_len:]\n            \n    return audios","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:42:24.395648Z","iopub.execute_input":"2023-10-31T18:42:24.396180Z","iopub.status.idle":"2023-10-31T18:42:24.406740Z","shell.execute_reply.started":"2023-10-31T18:42:24.396152Z","shell.execute_reply":"2023-10-31T18:42:24.405839Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"X = []\ny = []\n\nfor _, row in data.iterrows():\n\n    audios = audio_to_stft(row['filepath'], row.drop(['filepath', 'titre']), 22500)\n    \n    for audio in audios:\n        \n        # adding normal audio\n        X.append(audio.reshape(171, -1, 3))\n        y.append(row.drop(['filepath', 'titre']))","metadata":{"execution":{"iopub.status.busy":"2023-10-31T18:42:24.410804Z","iopub.execute_input":"2023-10-31T18:42:24.411050Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del data, iemo_data, rav_data, tess_data\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max = 0\nfor x in X:\n    max1 = np.max(np.abs(x))\n    if max < max1:\n        max = max1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_np = np.array(X, dtype=np.float16) / max\ny_np = np.array(y, dtype=np.float16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SPEC_SHAPE = X_np.shape[1:-1]\nSPEC_SHAPE","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"size = X_np.shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = np.copy(X_np[:int(size*0.9)])\ny_train = np.copy(y_np[:int(size*0.9)])\nX_test = np.copy(X_np[int(size*0.9):])\ny_test = np.copy(y_np[int(size*0.9):])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del X_np\ndel y_np\ndel X\ndel y\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Xtr, Xte, ytr, yte = train_test_split(X_np, y_np, test_size=0.2, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet50 = VGG19(\n    include_top = False, \n    weights = 'imagenet',\n    input_shape=SPEC_SHAPE + (3,),\n)\n\n# freeze layers\nfor layer in resnet50.layers:\n    layer.trainable = False\n    \nx = Flatten()(resnet50.output)\npred_layer = Dense(10, activation='sigmoid')(x)\n\nmodel = Model(inputs=resnet50.input, outputs=pred_layer)\nmodel.summary()\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    loss='categorical_crossentropy',\n    optimizer=Adam(learning_rate=1e-3),\n    metrics=['accuracy']\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# early_stopper = EarlyStopping(monitor = 'val_loss', patience = 3)\n# model_save = ModelCheckpoint(filepath='models/', monitor='val_losss')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fit_history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"name = 'modelvgg19-without-noice-50-48'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(f'{name}.h5') # 0.44 -> 0.40\njoblib.dump(model, f'{name}.pkl')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FileLink(f'{name}.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FileLink(f'{name}.pkl')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}